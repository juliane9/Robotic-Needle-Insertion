{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f138e51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /content/*.zip\n",
    "!unzip -q /content/train.zip -d /content/train\n",
    "!unzip -q /content/val.zip   -d /content/val\n",
    "!unzip -q /content/test.zip  -d /content/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eae07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imagecodecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a042ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "\n",
    "TRAIN_DIR = '/content/train/train'\n",
    "VAL_DIR   = '/content/val/val'\n",
    "\n",
    "IMG_SIZE   = 128\n",
    "BATCH_SIZE = 32\n",
    "LR         = 1e-4\n",
    "EPOCHS     = 50\n",
    "\n",
    "smooth = 1.0\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    inter = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * inter + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1.0 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d9014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split(folder):\n",
    "    \"\"\"Loads all .tif images and their _mask.tif from `folder`, resizes to IMG_SIZE.\"\"\"\n",
    "    fns = sorted(f for f in os.listdir(folder) if f.endswith('.tif') and '_mask' not in f)\n",
    "    N = len(fns)\n",
    "    X = np.zeros((N, IMG_SIZE, IMG_SIZE, 1), dtype=np.float32)\n",
    "    Y = np.zeros((N, IMG_SIZE, IMG_SIZE, 1), dtype=np.float32)\n",
    "    for i, fn in enumerate(tqdm(fns, desc=f'Loading {folder}')):\n",
    "        img = (Image.open(os.path.join(folder, fn))\n",
    "                  .convert('L')\n",
    "                  .resize((IMG_SIZE,IMG_SIZE), Image.BILINEAR))\n",
    "        msk = (Image.open(os.path.join(folder, fn.replace('.tif','_mask.tif')))\n",
    "                  .convert('L')\n",
    "                  .resize((IMG_SIZE,IMG_SIZE), Image.NEAREST))\n",
    "        X[i,...,0] = np.array(img)/255.0\n",
    "        Y[i,...,0] = (np.array(msk)>0).astype(np.float32)\n",
    "    return X, Y\n",
    "\n",
    "X_train, y_train = load_split(TRAIN_DIR)\n",
    "X_val,   y_val   = load_split(VAL_DIR)\n",
    "print(f\"Train shapes: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\" Val shapes: {X_val.shape},   {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40233bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(input_size=(IMG_SIZE,IMG_SIZE,1)):\n",
    "    inp = layers.Input(input_size)\n",
    "    def conv_block(x, f):\n",
    "        x = layers.Conv2D(f,3,padding='same',activation='relu')(x)\n",
    "        x = layers.Conv2D(f,3,padding='same',activation='relu')(x)\n",
    "        return x\n",
    "\n",
    "    c1 = conv_block(inp, 64); p1 = layers.MaxPooling2D()(c1)\n",
    "    c2 = conv_block(p1,128); p2 = layers.MaxPooling2D()(c2)\n",
    "    c3 = conv_block(p2,256); p3 = layers.MaxPooling2D()(c3)\n",
    "    c4 = conv_block(p3,512); p4 = layers.MaxPooling2D()(c4)\n",
    "\n",
    "    c5 = conv_block(p4,1024)\n",
    "\n",
    "    u6 = layers.Conv2DTranspose(512,2,strides=2,padding='same')(c5)\n",
    "    u6 = layers.concatenate([u6,c4]); c6 = conv_block(u6,512)\n",
    "    u7 = layers.Conv2DTranspose(256,2,strides=2,padding='same')(c6)\n",
    "    u7 = layers.concatenate([u7,c3]); c7 = conv_block(u7,256)\n",
    "    u8 = layers.Conv2DTranspose(128,2,strides=2,padding='same')(c7)\n",
    "    u8 = layers.concatenate([u8,c2]); c8 = conv_block(u8,128)\n",
    "    u9 = layers.Conv2DTranspose(64,2,strides=2,padding='same')(c8)\n",
    "    u9 = layers.concatenate([u9,c1]); c9 = conv_block(u9,64)\n",
    "\n",
    "    out = layers.Conv2D(1,1,activation='sigmoid')(c9)\n",
    "    return models.Model(inp,out)\n",
    "\n",
    "model = build_unet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d323da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.Adam(LR),\n",
    "    loss=dice_loss,\n",
    "    metrics=[dice_coef, 'binary_accuracy']\n",
    ")\n",
    "\n",
    "chkpt = callbacks.ModelCheckpoint(\n",
    "    'best_unet.h5',\n",
    "    monitor='val_dice_coef',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "csvlog = callbacks.CSVLogger('training.log')\n",
    "\n",
    "class BraCallback(callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(\"bra\")\n",
    "bra_cb = BraCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0107552",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[chkpt, csvlog, bra_cb],\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2596c496",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best_unet.h5')\n",
    "res = model.evaluate(X_val, y_val, batch_size=BATCH_SIZE, verbose=2)\n",
    "print(f\"VAL â†’  loss: {res[0]:.4f}   dice: {res[1]:.4f}   acc: {res[2]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
